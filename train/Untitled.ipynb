{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dcc51e8a-9420-4747-a27c-316596b24648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape (112, 67)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m model_pca\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Data augmentation during training\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m history_pca \u001b[38;5;241m=\u001b[39m model_pca\u001b[38;5;241m.\u001b[39mfit(datagen\u001b[38;5;241m.\u001b[39mflow(X_train_pca, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m), \n\u001b[0;32m     74\u001b[0m                             validation_data\u001b[38;5;241m=\u001b[39m(X_test_pca, y_test), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m     77\u001b[0m y_pred_pca \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(model_pca\u001b[38;5;241m.\u001b[39mpredict(X_test_pca), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1103\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1091\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1102\u001b[0m ):\n\u001b[1;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NumpyArrayIterator(\n\u001b[0;32m   1104\u001b[0m         x,\n\u001b[0;32m   1105\u001b[0m         y,\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1107\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1108\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1109\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1110\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1111\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1112\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1113\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1114\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1115\u001b[0m         ignore_class_split\u001b[38;5;241m=\u001b[39mignore_class_split,\n\u001b[0;32m   1116\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1118\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:612\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc \u001b[38;5;241m=\u001b[39m x_misc\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data in `NumpyArrayIterator` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 4. You passed an array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m     )\n\u001b[0;32m    617\u001b[0m channels_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[channels_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m}:\n",
      "\u001b[1;31mValueError\u001b[0m: Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape (112, 67)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "image_dir = r\"C:/Users/HOME/dacpvsrn\"\n",
    "image_size = (100, 100)  # Resize all images to 100x100\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img_resized = cv2.resize(img, image_size)\n",
    "                images.append(img_resized)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load images\n",
    "images = load_images_from_folder(image_dir)\n",
    "\n",
    "# Normalize images\n",
    "images = images / 255.0\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create fake labels for now (you can modify this part with actual labels)\n",
    "labels = np.random.randint(0, 10, len(images))  # Assume 10 classes\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten images for PCA\n",
    "X_train_flat = X_train.reshape(len(X_train), -1)\n",
    "X_test_flat = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "# 2. PCA-based Face Recognition\n",
    "pca = PCA(n_components=0.95, svd_solver='full')  # Capture 95% variance\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "X_test_pca = pca.transform(X_test_flat)\n",
    "\n",
    "# Simple Neural Network for classification using PCA components\n",
    "model_pca = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_pca.shape[1],)),\n",
    "    Dropout(0.3),  # Regularization with dropout\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Adjust based on the number of classes\n",
    "])\n",
    "\n",
    "# Compile with a lower learning rate for better convergence\n",
    "model_pca.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation during training\n",
    "history_pca = model_pca.fit(datagen.flow(X_train_pca, y_train, batch_size=32), \n",
    "                            validation_data=(X_test_pca, y_test), epochs=30)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_pca = np.argmax(model_pca.predict(X_test_pca), axis=-1)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "precision_pca = precision_score(y_test, y_pred_pca, average='weighted')\n",
    "recall_pca = recall_score(y_test, y_pred_pca, average='weighted')\n",
    "f1_pca = f1_score(y_test, y_pred_pca, average='weighted')\n",
    "\n",
    "# 3. Neural Network-based Face Recognition (No PCA)\n",
    "model_nn = Sequential([\n",
    "    Flatten(input_shape=image_size),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Adjust based on the number of classes\n",
    "])\n",
    "\n",
    "# Compile model with similar optimizer adjustments\n",
    "model_nn.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the neural network model\n",
    "history_nn = model_nn.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                          validation_data=(X_test, y_test), epochs=30)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_nn = np.argmax(model_nn.predict(X_test), axis=-1)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "precision_nn = precision_score(y_test, y_pred_nn, average='weighted')\n",
    "recall_nn = recall_score(y_test, y_pred_nn, average='weighted')\n",
    "f1_nn = f1_score(y_test, y_pred_nn, average='weighted')\n",
    "\n",
    "# 4. Comparison of results\n",
    "print(\"PCA-based Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_pca:.2f}, Precision: {precision_pca:.2f}, Recall: {recall_pca:.2f}, F1 Score: {f1_pca:.2f}\")\n",
    "\n",
    "print(\"\\nNeural Network-based Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_nn:.2f}, Precision: {precision_nn:.2f}, Recall: {recall_nn:.2f}, F1 Score: {f1_nn:.2f}\")\n",
    "\n",
    "# Plot loss and accuracy over epochs for both models\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# PCA Model\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_pca.history['accuracy'], label='PCA Model Training Accuracy')\n",
    "plt.plot(history_pca.history['val_accuracy'], label='PCA Model Validation Accuracy')\n",
    "plt.title('PCA Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# NN Model\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_nn.history['accuracy'], label='NN Model Training Accuracy')\n",
    "plt.plot(history_nn.history['val_accuracy'], label='NN Model Validation Accuracy')\n",
    "plt.title('NN Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd0a04-f382-4170-a206-696e4221c89d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
